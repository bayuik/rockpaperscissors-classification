# -*- coding: utf-8 -*-
"""submission_Bayuik.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/bayuik/rockpaperscissors-classification/blob/main/submission_Bayuik.ipynb

## Rock Paper Scissors Clasification
Nama : Bayu Indra Kusuma

Submission : Belajar Machine Learning Untuk Pemula

https://www.dicoding.com/users/bayuik

# Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import zipfile
import os
import shutil
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from keras.preprocessing import image
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D
from tensorflow.keras import Sequential
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.optimizers import Adam

# %matplotlib inline

"""# Gathering Data"""

!wget --no-check-certificate \
https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
-O rockpaperscissors.zip

local_zip = 'rockpaperscissors.zip'
with zipfile.ZipFile(local_zip, 'r') as zip_ref:
  zip_ref.extractall('/content')
  os.remove(local_zip)

"""# Create Directory for Training and Validation

## Function to Create and Copy Images to Directory
"""

dataset_dir = ['rock', 'paper', 'scissors']

def create_directory(directory):
  if not os.path.exists(directory):
    os.makedirs(directory)

def copy_images(source_dir, dest_dir, img_list):
  for img in img_list:
    shutil.copy(os.path.join(source_dir, img), os.path.join(dest_dir, img))

"""## Create Training and Validation Directory"""

for i in range(len(dataset_dir)):
  create_directory(f'train/{dataset_dir[i]}')
  create_directory(f'val/{dataset_dir[i]}')

"""## Split Dataset to Training and Validation"""

train_rock_dir, val_rock_dir = train_test_split(os.listdir('rockpaperscissors/rock'), test_size=0.4)
train_paper_dir, val_paper_dir = train_test_split(os.listdir('rockpaperscissors/paper'), test_size = 0.40)
train_scissors_dir, val_scissors_dir = train_test_split(os.listdir('rockpaperscissors/scissors'), test_size = 0.40)

"""## Copy Images to Training and Validation Directory"""

for i in range(len(dataset_dir)):
  copy_images(f'rockpaperscissors/{dataset_dir[i]}', f'train/{dataset_dir[i]}', globals()[f'train_{dataset_dir[i]}_dir'] )
  copy_images(f'rockpaperscissors/{dataset_dir[i]}', f'val/{dataset_dir[i]}', globals()[f'train_{dataset_dir[i]}_dir'])

"""# ImageDataGenerator for Augmented the Datasets"""

train_datagen = ImageDataGenerator(
                    rescale = 1./255,
                    rotation_range = 20,
                    horizontal_flip = True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    'train',
    target_size = (150, 150),
    batch_size = 32,
    class_mode = 'categorical')

validation_generator = test_datagen.flow_from_directory(
    'val',
    target_size = (150, 150),
    batch_size = 32,
    class_mode = 'categorical')

"""# Convolutional Neural Network for Image Classification"""

model = Sequential([
    Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Conv2D(128,(3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dropout(0.3),
    Dense(256, activation = 'relu'),
    Dropout(0.3),
    Dense(128, activation = 'relu'),
    Dense(3, activation = 'softmax')
])

model.summary()
model.compile(loss='categorical_crossentropy',
              optimizer=Adam(),
              metrics=['accuracy'])

"""# Callback to Stop Training When the"""

class stopTraining(Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.97):
      self.model.stop_training = True

callbacks = stopTraining()

"""# Training the model"""

history = model.fit(
    train_generator,
    steps_per_epoch=41,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=27,
    verbose=2,
    callbacks=[callbacks]
)

print(history.history.keys())

"""# Visualization"""

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(loss, label='Training', color='red')
plt.plot(val_loss, label='Validation', color='green')
plt.title('Model Loss')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc='upper right')
plt.show()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

plt.plot(acc, label='Training', color='red')
plt.plot(val_acc, label='Validation', color='green')
plt.title('Model Accuracy')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc='lower right')
plt.show()

"""# Test the Model With Image"""

uploaded = files.upload()
for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  print(fn)
  if classes[0,0]!=0:
    print('Paper')
  elif classes[0,1]!=0:
    print('Rock')
  else:
    print('Scissors')